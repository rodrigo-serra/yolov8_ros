#!/usr/bin/env python3
import cv2 as cv
import numpy as np
import rospy, sys, time, random

from cv_bridge import CvBridge, CvBridgeError

from std_msgs.msg import String

from ultralytics import YOLO
from ultralytics.engine.results import Results
from ultralytics.engine.results import Boxes
from ultralytics.engine.results import Masks
from ultralytics.engine.results import Keypoints
from ultralytics.utils.plotting import Annotator, colors
from torch import cuda

from sensor_msgs.msg import Image
from yolov8_ros.msg import Point2D
from yolov8_ros.msg import BoundingBox2D
from yolov8_ros.msg import Mask
from yolov8_ros.msg import KeyPoint2D
from yolov8_ros.msg import KeyPoint2DArray
from yolov8_ros.msg import Detection
from yolov8_ros.msg import DetectionArray


class Yolov8Node(object):
    def __init__(self):
        rospy.logwarn("Initializing yolov8_node")

        self.cv_bridge = CvBridge()
        self._last_msg = None
        self._seq_counter = 0
        
        self._currentEvent = "e_start"
        self._previousEvent = None
        self.new_image_frame = False
        self.first_detection = False
        
        self.yolo = None
        self._class_to_color = {}

        # Available class names
        available_class_names = {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 
            8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 
            16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 
            25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 
            33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 
            40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 
            49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 
            58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 
            67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 
            76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}
        
        # ROS Params specified in the launch file
        self.model = self.load_param('~model', 'yolov8m.pt')
        self.tracker = self.load_param('~tracker', 'bytetrack.yaml')
        self.device = self.load_param('~device', 'cuda:0')
        self.threshold = self.load_param('~threshold', 0.5)
        self.img_topic = self.load_param('~input', '/camera/rgb/image_raw')
        # self.reliability = self.load_param('~image_reliability', 2)
        
        self._readImgCompressed = self.load_param("~img_compressed", False)
        self._visualization = self.load_param('~visualization', False)
        self.enable_tracking = self.load_param('~enable_tracking', False)
        
        self.filter_by_class = self.load_param('~filter_by_class', False)
        class_names_to_filter = self.load_param('~classes', None)
        class_names_to_filter = class_names_to_filter.strip('][').split(', ')
        self.class_names_to_filter_by_id = None

        if self.filter_by_class:
            self.class_names_to_filter_by_id = self.get_ids_by_classes(class_names=class_names_to_filter, available_class_names=available_class_names)


        # Publishers and Subscribers
        self._event_sub = rospy.Subscriber("~event_in", String, self.eventCallback)
        
        if self._currentEvent != 'e_start':
            self.on_activate()
        
        self._pub = rospy.Publisher('~detections', DetectionArray, queue_size=10)
        self._vis_pub = rospy.Publisher('~visualization', Image, queue_size=2)
        
        self.start_time = time.time()
        rospy.logwarn("Initialized")

    
    def get_ids_by_classes(self, class_names, available_class_names):
        ids = []
        for class_id, class_name in available_class_names.items():
            if class_name in class_names:
                ids.append(class_id)
        return ids


    def on_activate(self):
        rospy.logwarn("Starting yolov8_node Topics!")
        self.yolo = YOLO(self.model)
        self.yolo.fuse()
        if self._readImgCompressed:
            self._sub = rospy.Subscriber(self.img_topic, CompressedImage, self.callback_image, queue_size=2)
        else:
            self._sub = rospy.Subscriber(self.img_topic, Image, self.callback_image, queue_size=2)


    def on_deactivate(self):
        rospy.logwarn("Stopping yolov8_node Topics!")
        del self.yolo
        if 'cuda' in self.device:
            rospy.logwarn("Clearing CUDA cache")
            cuda.empty_cache()

        self._previousEvent = self._currentEvent
        self._currentEvent = None
        img_msg = None
        self._last_msg = None
        self.first_detection = False
        self._sub.unregister()


    def manageEventIn(self):
        if self._currentEvent == "e_stop" and self._previousEvent != self._currentEvent:
            self.on_deactivate()
        
        if self._currentEvent == "kill" and self._previousEvent != self._currentEvent:
            rospy.signal_shutdown('Killing yolov8_node as issued by user')

        if self._currentEvent == "e_start" and self._previousEvent != self._currentEvent:
            self._previousEvent = self._currentEvent
            self._currentEvent = None
            self.on_activate()


    def parse_hypothesis(self, results):

        hypothesis_list = []

        # box_data = Boxes()
        for box_data in results.boxes:
            if self.enable_tracking:
                if box_data.id != None:
                    hypothesis = {
                        "class_id": int(box_data.cls),
                        "class_name": self.yolo.names[int(box_data.cls)],
                        "score": float(box_data.conf),
                        "track_id": str(int(box_data.id))
                    }
                else:
                    hypothesis = {
                        "class_id": int(box_data.cls),
                        "class_name": self.yolo.names[int(box_data.cls)],
                        "score": float(box_data.conf),
                        "track_id": 'None'
                    }
            else:
                hypothesis = {
                    "class_id": int(box_data.cls),
                    "class_name": self.yolo.names[int(box_data.cls)],
                    "score": float(box_data.conf)
                }
            
            hypothesis_list.append(hypothesis)

        return hypothesis_list


    def parse_boxes(self, results):

        boxes_list = []

        # box_data = Boxes()
        for box_data in results.boxes:

            msg = BoundingBox2D()

            # get boxes values
            box = box_data.xywh[0]
            msg.center.position.x = float(box[0])
            msg.center.position.y = float(box[1])
            msg.size.x = float(box[2])
            msg.size.y = float(box[3])

            # append msg
            boxes_list.append(msg)

        return boxes_list


    def create_point2d(self, x, y):
        p = Point2D()
        p.x = x
        p.y = y
        return p

    def parse_masks(self, results):
        masks_list = []
        # mask = Masks()
        for mask in results.masks:
            msg = Mask()
            
            msg.data = [self.create_point2d(float(ele[0]), float(ele[1]))
                        for ele in mask.xy[0].tolist()]
            msg.height = results.orig_img.shape[0]
            msg.width = results.orig_img.shape[1]

            masks_list.append(msg)

        return masks_list

    def parse_keypoints(self, results):

        keypoints_list = []

        # points = Keypoints()
        for points in results.keypoints:

            msg_array = KeyPoint2DArray()

            if points.conf is None:
                continue

            for kp_id, (p, conf) in enumerate(zip(points.xy[0], points.conf[0])):

                if conf >= self.threshold:
                    msg = KeyPoint2D()

                    msg.id = kp_id + 1
                    msg.point.x = float(p[0])
                    msg.point.y = float(p[1])
                    msg.score = float(conf)

                    msg_array.data.append(msg)

            keypoints_list.append(msg_array)

        return keypoints_list


    def run(self):
        rate = rospy.Rate(20)
        while not rospy.is_shutdown():

            self.manageEventIn()

            if self.new_image_frame:
                if self._last_msg is not None:
                    if not self.first_detection:
                        rospy.loginfo("Detecting images... (this message will not be published again)")
                        self.first_detection = True

                    # timeStamp = self._last_msg.header.stamp
                    timeStamp = self._last_msg.header
                    # frame_id = self._last_msg.header.frame_id

                    if self._readImgCompressed:
                        cv_image = self.convert_to_cv_image_compressed(self._last_msg)
                    else:
                        cv_image = self.convert_to_cv_image(self._last_msg)

                    
                    if self.enable_tracking:
                        results = self.yolo.track(
                            source=cv_image, 
                            tracker=self.tracker, 
                            persist=True,
                            stream=False,
                            conf=self.threshold, 
                            device=self.device,
                            classes=self.class_names_to_filter_by_id
                        )
                    else:
                        results = self.yolo.predict(
                            source=cv_image,
                            verbose=False,
                            stream=False,
                            conf=self.threshold,
                            device=self.device,
                            classes=self.class_names_to_filter_by_id
                        )

                    
                    results = results[0].cpu()
                    
                    if results.boxes:
                        hypothesis = self.parse_hypothesis(results)
                        boxes = self.parse_boxes(results)

                    if results.masks:
                        masks = self.parse_masks(results)

                    if results.keypoints:
                        keypoints = self.parse_keypoints(results)

                    # create detection msgs
                    detections_msg = DetectionArray()
                    
                    for i in range(len(results)):

                        aux_msg = Detection()

                        if results.boxes:
                            if self.enable_tracking:
                                aux_msg.id = hypothesis[i]["track_id"]

                            aux_msg.class_id = hypothesis[i]["class_id"]
                            aux_msg.class_name = hypothesis[i]["class_name"]
                            aux_msg.score = hypothesis[i]["score"]

                            aux_msg.bbox = boxes[i]

                        if results.masks:
                            aux_msg.mask = masks[i]

                        if results.keypoints:
                            aux_msg.keypoints = keypoints[i]

                        detections_msg.detections.append(aux_msg)

                    if detections_msg != None:
                        # publish detections
                        # detections_msg.header = timeStamp
                        self._pub.publish(detections_msg)
                        if self._visualization:
                            self.drawDetections(cv_image, detections_msg, timeStamp)

                    del results
                    del cv_image

                self._last_msg = None
                self.new_image_frame = False
            else:
                rate.sleep()

    
    def drawDetections(self, cv_image, detection_msg, timeStamp):

        # cv_image = self.cv_bridge.imgmsg_to_cv2(img_msg)
        # bb_marker_array = MarkerArray()
        # kp_marker_array = MarkerArray()

        for detection in detection_msg.detections:

            # random color
            label = detection.class_name

            if label not in self._class_to_color:
                r = random.randint(0, 255)
                g = random.randint(0, 255)
                b = random.randint(0, 255)
                self._class_to_color[label] = (r, g, b)

            color = self._class_to_color[label]

            cv_image = self.draw_box(cv_image, detection, color)
            cv_image = self.draw_mask(cv_image, detection, color)
            cv_image = self.draw_keypoints(cv_image, detection)

            # if detection.bbox3d.frame_id:
            #     marker = self.create_bb_marker(detection, color)
            #     marker.header.stamp = img_msg.header.stamp
            #     marker.id = len(bb_marker_array.markers)
            #     bb_marker_array.markers.append(marker)

            # if detection.keypoints3d.frame_id:
            #     for kp in detection.keypoints3d.data:
            #         marker = self.create_kp_marker(kp)
            #         marker.header.frame_id = detection.keypoints3d.frame_id
            #         marker.header.stamp = img_msg.header.stamp
            #         marker.id = len(kp_marker_array.markers)
            #         kp_marker_array.markers.append(marker)

        
        # publish dbg image
        image_msg = self.cv_bridge.cv2_to_imgmsg(cv_image)
        image_msg.header.stamp = timeStamp.stamp
        self._vis_pub.publish(image_msg)

        # self._bb_markers_pub.publish(bb_marker_array)
        # self._kp_markers_pub.publish(kp_marker_array)


    def draw_box(self, cv_image, detection, color):
        # Get detection info
        label = detection.class_name
        score = detection.score
        box_msg = detection.bbox
        track_id = detection.id

        # Calculate box coordinates
        top_left = (int(box_msg.center.position.x - box_msg.size.x / 2.0),
                    int(box_msg.center.position.y - box_msg.size.y / 2.0))
        bottom_right = (int(box_msg.center.position.x + box_msg.size.x / 2.0),
                        int(box_msg.center.position.y + box_msg.size.y / 2.0))

        # Draw bounding box
        cv.rectangle(cv_image, top_left, bottom_right, color, 2)

        # Write text
        text = f"{label} ({track_id}) ({score:.3f})"
        text_size, _ = cv.getTextSize(text, cv.FONT_HERSHEY_SIMPLEX, 0.5, 2)
        text_position = (top_left[0], top_left[1] - 10)
        cv.rectangle(cv_image, (text_position[0], text_position[1] - text_size[1]),
                    (text_position[0] + text_size[0], text_position[1] + text_size[1]), color, -1)
        cv.putText(cv_image, text, text_position, cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        return cv_image


    def draw_mask(self, cv_image, detection, color):

        mask_msg = detection.mask
        
        mask_array = np.array([[int(ele.x), int(ele.y)]for ele in mask_msg.data])

        if mask_msg.data:
            layer = cv_image.copy()
            layer = cv.fillPoly(layer, pts=[mask_array], color=color)
            cv.addWeighted(cv_image, 0.4, layer, 0.6, 0, cv_image)
            cv_image = cv.polylines(cv_image, [mask_array], isClosed=True, color=color, thickness=2, lineType=cv.LINE_AA)

        return cv_image

    
    def get_pk_pose(self, kp_id, keypoints_msg):
        for kp in keypoints_msg.data:
            if kp.id == kp_id:
                return (int(kp.point.x), int(kp.point.y))
        return None
    
    
    def draw_keypoints(self, cv_image, detection):

        keypoints_msg = detection.keypoints

        ann = Annotator(cv_image)

        kp = KeyPoint2D()
        for kp in keypoints_msg.data:
            color_k = [int(x) for x in ann.kpt_color[kp.id - 1]] if len(keypoints_msg.data) == 17 else colors(kp.id - 1)

            cv.circle(cv_image, (int(kp.point.x), int(kp.point.y)),5, color_k, -1, lineType=cv.LINE_AA)

        for i, sk in enumerate(ann.skeleton):
            kp1_pos = self.get_pk_pose(sk[0], keypoints_msg)
            kp2_pos = self.get_pk_pose(sk[1], keypoints_msg)

            if kp1_pos is not None and kp2_pos is not None:
                cv.line(cv_image, kp1_pos, kp2_pos, [int(x) for x in ann.limb_color[i]], thickness=2, lineType=cv.LINE_AA)

        return cv_image



    
    def convert_to_cv_image(self, image_msg):

        if image_msg is None:
            return None

        self._width = image_msg.width
        self._height = image_msg.height
        channels = int(len(image_msg.data) / (self._width * self._height))

        encoding = None
        if image_msg.encoding.lower() in ['rgb8', 'bgr8', 'bgra8']:
            encoding = np.uint8
        elif image_msg.encoding.lower() == 'mono8':
            encoding = np.uint8
        elif image_msg.encoding.lower() == '32fc1':
            encoding = np.float32
            channels = 1

        cv_img = np.ndarray(shape=(image_msg.height, image_msg.width, channels),
                            dtype=encoding, buffer=image_msg.data)

        if image_msg.encoding.lower() == 'mono8':
            cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2GRAY)
        elif image_msg.encoding.lower() == 'bgra8':
            cv_img = cv.cvtColor(cv_img, cv.COLOR_BGRA2BGR)
        else:
            cv_img = cv.cvtColor(cv_img, cv.COLOR_RGB2BGR)

        return cv_img

    
    def convert_to_cv_image_compressed(self, image_msg):
        try:
            return self._bridge.compressed_imgmsg_to_cv2(image_msg, "bgr8")
        except CvBridgeError as e:
            rospy.logerr(e)


    def callback_image(self, msg):
        rospy.logdebug("Get an image")
        if not self.new_image_frame:
            self._last_msg = msg
            self.new_image_frame = True


    def eventCallback(self, data):
        self._currentEvent = data.data


    @staticmethod
    def load_param(param, default=None):
        new_param = rospy.get_param(param, default)
        rospy.loginfo("[yolov8_node] %s: %s", param, new_param)
        return new_param


def main(argv):
    rospy.init_node('yolov8_node')
    node = Yolov8Node()
    node.run()

if __name__ == '__main__':
    main(sys.argv)
